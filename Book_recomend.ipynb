{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93abfe3e-be2e-4af0-85dc-059604e00005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/ki/miniforge3/lib/python3.10/site-packages (from sentence-transformers) (4.66.2)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.3.1-cp310-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting numpy (from sentence-transformers)\n",
      "  Downloading numpy-2.0.0-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.14.0-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.15.1 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-10.3.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/ki/miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in /Users/ki/miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp310-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.0-cp310-cp310-macosx_14_0_arm64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp310-cp310-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading scikit_learn-1.5.0-cp310-cp310-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp310-cp310-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp310-cp310-macosx_11_0_arm64.whl (169 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.3/169.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-macosx_11_0_arm64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-macosx_11_0_arm64.whl (410 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.9/410.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_universal2.whl (18 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, threadpoolctl, sympy, safetensors, regex, pyyaml, Pillow, numpy, networkx, MarkupSafe, joblib, fsspec, filelock, scipy, jinja2, huggingface-hub, torch, tokenizers, scikit-learn, transformers, sentence-transformers\n",
      "Successfully installed MarkupSafe-2.1.5 Pillow-10.3.0 filelock-3.15.4 fsspec-2024.6.0 huggingface-hub-0.23.4 jinja2-3.1.4 joblib-1.4.2 mpmath-1.3.0 networkx-3.3 numpy-2.0.0 pyyaml-6.0.1 regex-2024.5.15 safetensors-0.4.3 scikit-learn-1.5.0 scipy-1.14.0 sentence-transformers-3.0.1 sympy-1.12.1 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.3.1 transformers-4.41.2 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de42fe05-46e4-46b4-8154-f11741f596a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/ki/miniforge3/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: tensorflow in /Users/ki/miniforge3/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py in /Users/ki/miniforge3/lib/python3.10/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/ki/miniforge3/lib/python3.10/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /Users/ki/miniforge3/lib/python3.10/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/ki/miniforge3/lib/python3.10/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /Users/ki/miniforge3/lib/python3.10/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /Users/ki/miniforge3/lib/python3.10/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /Users/ki/miniforge3/lib/python3.10/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: packaging in /Users/ki/miniforge3/lib/python3.10/site-packages (from keras) (24.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (0.5.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: tensorflow in /Users/ki/miniforge3/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (0.5.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /Users/ki/miniforge3/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/ki/miniforge3/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/ki/miniforge3/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ki/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ki/miniforge3/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ki/miniforge3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras tensorflow\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6697a39c-fdc7-490e-a631-957a1a8d9293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/ki/miniforge3/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ki/miniforge3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, python-dateutil, pandas\n",
      "Successfully installed pandas-2.2.2 python-dateutil-2.9.0.post0 pytz-2024.1 tzdata-2024.1\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading openpyxl-3.1.4-py2.py3-none-any.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.4/251.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "87a613c1-bffc-4e2a-9a0d-ab32f73c0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\kiwizcloud\\내 드라이브\\Dev\\Book_data_drop.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8480e3d2-6175-4878-a40e-4f8aa845131f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU 사용\n",
    "import torch\n",
    "torch.cuda.is_available() #True 반환하면 GPU 사용가능 상태 -> 다음 코드 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d53b5b64-0f25-4db9-970b-bf842043e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu') #Cuda(GPU)사용 가능하면 GPU사용, 아니면 CPU사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5179e8-e89d-4a88-83aa-ac366a33c943",
   "metadata": {},
   "source": [
    "# 1. 분류 모델 생성\n",
    "### (설명 + 목차 모두 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f2f239dc-1445-4076-897d-9c822b7324e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_excel(r\"C:\\Users\\kiwizcloud\\내 드라이브\\Dev\\Book_data_processed.xlsx\")\n",
    "df['introduction'] = df['introduction'].fillna('')\n",
    "df['contents'] = df['contents'].fillna('')\n",
    "df['combined_text'] = df['introduction'] + ' ' + df['contents']\n",
    "\n",
    "# 가중치 설정\n",
    "title_weight = 1.2  # 상품명 가중치\n",
    "author_weight = 1.0  # 작가 가중치\n",
    "category_weight = 1.0  # 대분류 가중치\n",
    "description_weight = 1.3  # 설명 가중치\n",
    "\n",
    "# 상품명 벡터화\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['title'])\n",
    "weighted_tfidf_matrix = title_weight * tfidf_matrix  # 가중치 부여\n",
    "\n",
    "# 작가 정보 벡터화\n",
    "author_vectorizer = TfidfVectorizer()\n",
    "author_matrix = author_vectorizer.fit_transform(df['author'])\n",
    "weighted_author_matrix = author_weight * author_matrix  # 가중치 부여\n",
    "\n",
    "# 대분류 정보 원-핫 인코딩\n",
    "category_encoder = OneHotEncoder()\n",
    "category_matrix = category_encoder.fit_transform(df[['category2']])\n",
    "weighted_category_matrix = category_weight * category_matrix  # 가중치 부여\n",
    "\n",
    "\n",
    "# BERT 모델 로드\n",
    "model_name = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "\n",
    "# BERT를 사용하여 설명 정보 벡터화\n",
    "def bert_vectorize(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# 결합 텍스트 벡터화\n",
    "description_vectors = df['combined_text'].apply(bert_vectorize)\n",
    "description_matrix = np.vstack(description_vectors.values)\n",
    "weighted_description_matrix = description_weight * description_matrix\n",
    "\n",
    "# 상품명, 작가, 대분류, 설명 정보를 결합하여 최종 행렬 생성\n",
    "final_matrix = hstack((weighted_tfidf_matrix, weighted_author_matrix, weighted_category_matrix, weighted_description_matrix)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794c864-5d9f-4f99-9dcc-66dc5498e486",
   "metadata": {},
   "source": [
    "## isbn추출 및 h5파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "879839d6-39b1-471b-b5c4-a6a79c3ff920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       9791198517425\n",
       "1       9791193937068\n",
       "2       9791198564139\n",
       "3       9791130653150\n",
       "4       9791191056372\n",
       "            ...      \n",
       "2003    9791192987965\n",
       "2004    9791191905755\n",
       "2005    9791193205235\n",
       "2006    9788931475388\n",
       "2007    9788965020110\n",
       "Name: isbn, Length: 2008, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['isbn'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "53bbb09d-809a-462a-a45f-48928f63b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isbn값 추출\n",
    "isbn_list = df['isbn'].astype('int64').tolist() #그냥 int형으로 저장하게 되면 오버플로우 발생해 isbn데이터 값이 깨짐\n",
    "\n",
    "# 최종 행렬을 DataFrame으로 변환하고 ISBN을 인덱스로 설정\n",
    "final_matrix_df = pd.DataFrame(final_matrix, index=isbn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f34a17eb-7511-4e76-9ff8-c8df1a7c2c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6393</th>\n",
       "      <th>6394</th>\n",
       "      <th>6395</th>\n",
       "      <th>6396</th>\n",
       "      <th>6397</th>\n",
       "      <th>6398</th>\n",
       "      <th>6399</th>\n",
       "      <th>6400</th>\n",
       "      <th>6401</th>\n",
       "      <th>6402</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9791198517425</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113871</td>\n",
       "      <td>0.351395</td>\n",
       "      <td>-0.529766</td>\n",
       "      <td>-1.277292</td>\n",
       "      <td>0.035310</td>\n",
       "      <td>-0.353148</td>\n",
       "      <td>0.136427</td>\n",
       "      <td>0.369242</td>\n",
       "      <td>0.488639</td>\n",
       "      <td>0.091147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791193937068</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171356</td>\n",
       "      <td>0.283931</td>\n",
       "      <td>-0.467369</td>\n",
       "      <td>-1.381355</td>\n",
       "      <td>0.016641</td>\n",
       "      <td>-0.456644</td>\n",
       "      <td>0.414899</td>\n",
       "      <td>0.377052</td>\n",
       "      <td>0.349531</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791198564139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223073</td>\n",
       "      <td>0.292066</td>\n",
       "      <td>-0.450192</td>\n",
       "      <td>-1.383421</td>\n",
       "      <td>0.091756</td>\n",
       "      <td>-0.432998</td>\n",
       "      <td>0.323660</td>\n",
       "      <td>0.494477</td>\n",
       "      <td>0.433761</td>\n",
       "      <td>-0.062013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791130653150</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145764</td>\n",
       "      <td>0.146797</td>\n",
       "      <td>-0.370518</td>\n",
       "      <td>-1.216604</td>\n",
       "      <td>0.041915</td>\n",
       "      <td>-0.262993</td>\n",
       "      <td>0.266227</td>\n",
       "      <td>0.360382</td>\n",
       "      <td>0.339611</td>\n",
       "      <td>0.153659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791191056372</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131984</td>\n",
       "      <td>0.353868</td>\n",
       "      <td>-0.609061</td>\n",
       "      <td>-1.296685</td>\n",
       "      <td>0.068275</td>\n",
       "      <td>-0.429050</td>\n",
       "      <td>0.226057</td>\n",
       "      <td>0.341837</td>\n",
       "      <td>0.404175</td>\n",
       "      <td>0.078428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791192987965</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083384</td>\n",
       "      <td>0.200328</td>\n",
       "      <td>-0.641535</td>\n",
       "      <td>-1.359036</td>\n",
       "      <td>0.059749</td>\n",
       "      <td>-0.266535</td>\n",
       "      <td>0.257491</td>\n",
       "      <td>0.582767</td>\n",
       "      <td>0.586813</td>\n",
       "      <td>-0.209493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791191905755</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170657</td>\n",
       "      <td>0.070015</td>\n",
       "      <td>-0.544429</td>\n",
       "      <td>-1.290481</td>\n",
       "      <td>0.027342</td>\n",
       "      <td>-0.342865</td>\n",
       "      <td>0.277322</td>\n",
       "      <td>0.496223</td>\n",
       "      <td>0.491489</td>\n",
       "      <td>-0.227157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791193205235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161930</td>\n",
       "      <td>0.261295</td>\n",
       "      <td>-0.358940</td>\n",
       "      <td>-1.311567</td>\n",
       "      <td>0.058679</td>\n",
       "      <td>-0.521033</td>\n",
       "      <td>0.388074</td>\n",
       "      <td>0.677100</td>\n",
       "      <td>0.397947</td>\n",
       "      <td>-0.060805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9788931475388</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202967</td>\n",
       "      <td>0.077903</td>\n",
       "      <td>-0.606460</td>\n",
       "      <td>-1.295104</td>\n",
       "      <td>-0.018945</td>\n",
       "      <td>-0.188948</td>\n",
       "      <td>0.290815</td>\n",
       "      <td>0.280895</td>\n",
       "      <td>0.356512</td>\n",
       "      <td>-0.113556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9788965020110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261128</td>\n",
       "      <td>0.082872</td>\n",
       "      <td>-0.443197</td>\n",
       "      <td>-1.362576</td>\n",
       "      <td>-0.047633</td>\n",
       "      <td>-0.430405</td>\n",
       "      <td>0.387804</td>\n",
       "      <td>0.410713</td>\n",
       "      <td>0.354582</td>\n",
       "      <td>-0.008571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2008 rows × 6403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4     5     6     7     8     9     \\\n",
       "9791198517425   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9791193937068   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9791198564139   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9791130653150   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9791191056372   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "...             ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "9791192987965   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9791191905755   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9791193205235   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9788931475388   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9788965020110   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "               ...      6393      6394      6395      6396      6397  \\\n",
       "9791198517425  ...  0.113871  0.351395 -0.529766 -1.277292  0.035310   \n",
       "9791193937068  ...  0.171356  0.283931 -0.467369 -1.381355  0.016641   \n",
       "9791198564139  ...  0.223073  0.292066 -0.450192 -1.383421  0.091756   \n",
       "9791130653150  ...  0.145764  0.146797 -0.370518 -1.216604  0.041915   \n",
       "9791191056372  ...  0.131984  0.353868 -0.609061 -1.296685  0.068275   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "9791192987965  ... -0.083384  0.200328 -0.641535 -1.359036  0.059749   \n",
       "9791191905755  ...  0.170657  0.070015 -0.544429 -1.290481  0.027342   \n",
       "9791193205235  ...  0.161930  0.261295 -0.358940 -1.311567  0.058679   \n",
       "9788931475388  ...  0.202967  0.077903 -0.606460 -1.295104 -0.018945   \n",
       "9788965020110  ...  0.261128  0.082872 -0.443197 -1.362576 -0.047633   \n",
       "\n",
       "                   6398      6399      6400      6401      6402  \n",
       "9791198517425 -0.353148  0.136427  0.369242  0.488639  0.091147  \n",
       "9791193937068 -0.456644  0.414899  0.377052  0.349531  0.000041  \n",
       "9791198564139 -0.432998  0.323660  0.494477  0.433761 -0.062013  \n",
       "9791130653150 -0.262993  0.266227  0.360382  0.339611  0.153659  \n",
       "9791191056372 -0.429050  0.226057  0.341837  0.404175  0.078428  \n",
       "...                 ...       ...       ...       ...       ...  \n",
       "9791192987965 -0.266535  0.257491  0.582767  0.586813 -0.209493  \n",
       "9791191905755 -0.342865  0.277322  0.496223  0.491489 -0.227157  \n",
       "9791193205235 -0.521033  0.388074  0.677100  0.397947 -0.060805  \n",
       "9788931475388 -0.188948  0.290815  0.280895  0.356512 -0.113556  \n",
       "9788965020110 -0.430405  0.387804  0.410713  0.354582 -0.008571  \n",
       "\n",
       "[2008 rows x 6403 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "632267c1-b2b1-4a0a-8837-08cd4c86f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# 최종 행렬을 h5 파일로 저장\n",
    "with h5py.File('final_matrix_isbn.h5', 'w') as h5_file:\n",
    "    h5_file.create_dataset('final_matrix', data=final_matrix_df.values)\n",
    "    h5_file.create_dataset('isbn_list', data=np.array(isbn_list), dtype=np.int64)\n",
    "    # h5py에서 데이터셋을 생성할 때는 데이터 형태를 명시적으로 지정해야함(int형)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eef1da-36b2-4f94-802b-6640b91685bf",
   "metadata": {},
   "source": [
    "### 저장내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "75f746fd-4436-4cb8-b825-31c55cae92b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['final_matrix', 'isbn_list']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(r\"C:\\Users\\kiwizcloud\\내 드라이브\\Dev\\final_matrix_isbn.h5\", 'r') as h5_file:\n",
    "    print(list(h5_file.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e93ed99-bf15-4001-81af-abdc8d4102ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9791198517425 9791193937068 9791198564139 ... 9791193205235 9788931475388\n",
      " 9788965020110]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(r\"C:\\Users\\kiwizcloud\\내 드라이브\\Dev\\final_matrix_isbn.h5\", 'r') as h5_file:\n",
    "    isbn_list = h5_file['isbn_list'][:]\n",
    "    print(isbn_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392fb75-25f4-4bb8-a98c-87ee9a50bfee",
   "metadata": {},
   "source": [
    "# 2. 추천과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d0a79c88-5005-4f33-bcd6-45423eaa77f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "찾고자 하는 책의 ISBN13을 입력하세요:  9791193926246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998\n",
      "'AWS 시스템 개발 스킬업' 책과 유사한 책:\n",
      "               isbn                 title    author category2\n",
      "1919  9791192987675    클라우드 네이티브 스프링 인 액션   토마스 비탈레    IT 모바일\n",
      "2003  9791192987965    러스트 서버, 서비스, 앱 만들기  프라부 에스왈라    IT 모바일\n",
      "1863  9791169212366  한 권으로 배우는 도커 & 쿠버네티스       장철원    IT 모바일\n",
      "1846  9791193926208             자바 잘 읽는 법  로렌티우 스필카    IT 모바일\n",
      "1987  9791190665209   그림으로 공부하는 IT 인프라 구조  야마자키 야스시    IT 모바일\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# ISBN13 값으로 책 찾기\n",
    "def find_book_by_isbn13(isbn13):\n",
    "    # ISBN13 값을 정수로 변환\n",
    "    isbn13 = int(isbn13)\n",
    "    book = df[df['isbn'] == isbn13]\n",
    "    if len(book) > 0:\n",
    "        print(book.index[0])\n",
    "        return book.index[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 유사도 계산 함수\n",
    "def get_top_similar_books(book_index, top_n=5):\n",
    "    # 코사인 유사도 계산\n",
    "    cosine_sim = cosine_similarity(final_matrix)\n",
    "\n",
    "    # 유클리디안 거리 계산\n",
    "    euclidean_dist = euclidean_distances(final_matrix)\n",
    "\n",
    "    # 거리 행렬을 유사도 행렬로 변환\n",
    "    euclidean_sim = 1 / (1 + euclidean_dist)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[book_index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [i for i, _ in sim_scores[1:top_n+1]]\n",
    "    top_books = df.iloc[top_indices][['isbn', 'title', 'author', 'category2']]\n",
    "    return top_books\n",
    "\n",
    "# 사용자로부터 ISBN13 값 입력 받기\n",
    "isbn13 = input(\"찾고자 하는 책의 ISBN13을 입력하세요: \")\n",
    "\n",
    "# ISBN13 값으로 책 찾기\n",
    "book_index = find_book_by_isbn13(isbn13)\n",
    "\n",
    "if book_index is not None:\n",
    "    # 유사한 책 찾기\n",
    "    top_similar_books = get_top_similar_books(book_index, top_n=5)\n",
    "    print(f\"'{df.loc[book_index, 'title']}' 책과 유사한 책:\")\n",
    "    print(top_similar_books)\n",
    "else:\n",
    "    print(\"해당 ISBN13을 가진 책이 존재하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927952c2-f5f1-4111-a0e0-77a013bb042e",
   "metadata": {},
   "source": [
    "# 3. 북카트 추천부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dd3b2487-895d-48f7-9be4-756a54a5656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q):  9791161726663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795\n",
      "'한 컷 쏙 과학사' 책이 북카트에 추가되었습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q):  9791188829408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072\n",
      "'특별하게 제주' 책이 북카트에 추가되었습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q):  9791190073240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1084\n",
      "'에이든 파리 여행지도' 책이 북카트에 추가되었습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q):  9788935703463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1579\n",
      "'왓칭 Watching' 책이 북카트에 추가되었습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q):  9791192987910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1918\n",
      "'초자동화 시대가 온다' 책이 북카트에 추가되었습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q):  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트를 기반으로 한 추천 책:\n",
      "               isbn          title   author category2\n",
      "1600  9791165219550        미적분의 쓸모      한화택      자연과학\n",
      "970   9791190073318    에이든 홍콩 여행지도    타블라라사     건강 취미\n",
      "1478  9791192625294        요약이 힘이다  사이토 다카시      자기계발\n",
      "1147  9791140706631  무작정 따라하기 싱가포르      전상현     건강 취미\n",
      "1258  9788998075088    상처 받지 않는 영혼   마이클 싱어        인문\n"
     ]
    }
   ],
   "source": [
    "# 사용자의 북카트 정보 저장\n",
    "user_cart = []\n",
    "\n",
    "# 북카트에 책 추가하는 함수\n",
    "def add_to_cart(isbn13):\n",
    "    book_index = find_book_by_isbn13(isbn13)\n",
    "    if book_index is not None:\n",
    "        user_cart.append(book_index)\n",
    "        print(f\"'{df.loc[book_index, 'title']}' 책이 북카트에 추가되었습니다.\")\n",
    "    else:\n",
    "        print(\"해당 ISBN13을 가진 책이 존재하지 않습니다.\")\n",
    "\n",
    "# 북카트를 기반으로 유사한 책 추천하는 함수\n",
    "def recommend_books_from_cart(top_n=5):\n",
    "    if len(user_cart) == 0:\n",
    "        print(\"북카트가 비어있습니다.\")\n",
    "        return\n",
    "\n",
    "    # 북카트에 담긴 책들의 유사도 점수 합산\n",
    "    cart_scores = np.zeros(len(df))\n",
    "    for book_index in user_cart:\n",
    "        cart_scores += cosine_similarity(final_matrix[book_index].reshape(1, -1), final_matrix)[0]\n",
    "\n",
    "    # 유사도 점수 기준으로 정렬\n",
    "    sim_scores = list(enumerate(cart_scores))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 북카트에 담긴 책들 제외하고 상위 N개 책 추천\n",
    "    top_indices = [i for i, _ in sim_scores if i not in user_cart][:top_n]\n",
    "    top_books = df.iloc[top_indices][['isbn', 'title', 'author', 'category2']]\n",
    "    return top_books\n",
    "\n",
    "# 사용자로부터 ISBN13 값 입력 받기\n",
    "while True:\n",
    "    isbn13 = input(\"북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q): \")\n",
    "    if isbn13 == 'q':\n",
    "        break\n",
    "    add_to_cart(isbn13)\n",
    "\n",
    "# 북카트 기반 책 추천\n",
    "recommended_books = recommend_books_from_cart(top_n=5)\n",
    "print(\"북카트를 기반으로 한 추천 책:\")\n",
    "print(recommended_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0db0d-1224-4cb4-b7c1-2086503b7de4",
   "metadata": {},
   "source": [
    "## np.mean사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b46202fb-2d36-41a0-b1a6-27c9b7dde36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q):  9788901260679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "'넛지: 파이널 에디션' 책이 북카트에 추가되었습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q):  9791188279807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "'볼린저 밴드 투자기법' 책이 북카트에 추가되었습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q):  9791171170418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "'일론 머스크' 책이 북카트에 추가되었습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q):  9791193059289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n",
      "'교실에서 바로 통하는 배움중심수업 에듀테크와 AI로 확!잡자' 책이 북카트에 추가되었습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q):  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "북카트를 기반으로 한 추천 책:\n",
      "              isbn                      title     author category2\n",
      "215  9788998075200                     사업의 철학     마이클 거버     경제 경영\n",
      "4    9791191056372  돈의 심리학 (30만 부 기념 스페셜 에디션)     모건 하우절     경제 경영\n",
      "107  9788960519831                        칩 워     크리스 밀러     경제 경영\n",
      "17   9791165349707                    AI 사피엔스        최재붕     경제 경영\n",
      "211  9791155816066                  AI 이후의 세계  헨리 A. 키신저     경제 경영\n"
     ]
    }
   ],
   "source": [
    "# 사용자의 북카트 정보 저장\n",
    "user_cart = []\n",
    "\n",
    "# 북카트에 책 추가하는 함수\n",
    "def add_to_cart(isbn13):\n",
    "    book_index = find_book_by_isbn13(isbn13)\n",
    "    if book_index is not None:\n",
    "        user_cart.append(book_index)\n",
    "        print(f\"'{df.loc[book_index, 'title']}' 책이 북카트에 추가되었습니다.\")\n",
    "    else:\n",
    "        print(\"해당 ISBN13을 가진 책이 존재하지 않습니다.\")\n",
    "\n",
    "# 북카트를 기반으로 유사한 책 추천하는 함수\n",
    "def recommend_books_from_cart(top_n=5):\n",
    "    if len(user_cart) == 0:\n",
    "        print(\"북카트가 비어있습니다.\")\n",
    "        return\n",
    "\n",
    "    individual_scores = []\n",
    "    for book_index in user_cart:\n",
    "        scores = cosine_similarity(final_matrix[book_index].reshape(1, -1), final_matrix)[0]\n",
    "        individual_scores.append(scores)\n",
    "\n",
    "    # 개별 유사도 점수 합산 방식 (예: 최대값 사용 -> 결과가 별로여서 평균값 사용)\n",
    "    combined_scores = np.mean(individual_scores, axis=0)\n",
    "\n",
    "    # 유사도 점수 기준으로 정렬\n",
    "    sim_scores = list(enumerate(combined_scores))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 북카트에 담긴 책들 제외하고 상위 N개 책 추천\n",
    "    top_indices = [i for i, _ in sim_scores if i not in user_cart][:top_n]\n",
    "    top_books = df.iloc[top_indices][['isbn', 'title', 'author', 'category2']]\n",
    "    return top_books\n",
    "\n",
    "# 사용자로부터 ISBN13 값 입력 받기\n",
    "while True:\n",
    "    isbn13 = input(\"북카트에 추가할 책의 ISBN13을 입력하세요 (종료: q): \")\n",
    "    if isbn13 == 'q':\n",
    "        break\n",
    "    add_to_cart(isbn13)\n",
    "\n",
    "# 북카트 기반 책 추천\n",
    "recommended_books = recommend_books_from_cart(top_n=5)\n",
    "print(\"북카트를 기반으로 한 추천 책:\")\n",
    "print(recommended_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695008b-02e4-47af-9e69-32f071040c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
